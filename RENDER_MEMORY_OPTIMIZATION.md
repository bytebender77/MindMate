# üîß Render Memory Optimization Guide

## ‚ùå Problem: Out of Memory Error

```
==> Out of memory (used over 512Mi)
```

**Issue**: The free tier on Render has only **512MB RAM**, and the GoEmotions model is large, causing the service to exceed memory limits during startup.

## ‚úÖ Solution: Lazy Loading

The model is now loaded **lazy** (on first request) instead of at startup, significantly reducing initial memory usage.

### Changes Made:

1. **Lazy Model Loading**: Model loads only when first needed
2. **Removed Startup Warmup**: No model loading during startup
3. **Memory-Efficient Settings**: Optimized model loading settings
4. **Fallback Model**: Lighter model available if needed

## üéØ Memory Optimization Strategies

### 1. Lazy Loading (Implemented)
- ‚úÖ Model loads on first request, not at startup
- ‚úÖ Saves ~200-300MB of memory during startup
- ‚úÖ First request may be slightly slower (30-60 seconds)

### 2. Use Lighter Model (Optional)
If memory issues persist, the code will automatically fallback to:
- **Model**: `j-hartmann/emotion-english-distilroberta-base`
- **Size**: ~300MB (vs ~500MB for GoEmotions)
- **Emotions**: 7 basic emotions (vs 27 for GoEmotions)
- **Memory**: ~50% less memory usage

### 3. Environment Variable to Force Lighter Model

You can set an environment variable to use the lighter model:

```env
USE_LIGHT_MODEL=true
```

Then update the code to check this variable.

### 4. Model Quantization (Advanced)

For even more memory savings, you can use quantized models:
- **8-bit quantization**: ~50% memory reduction
- **4-bit quantization**: ~75% memory reduction
- **Trade-off**: Slight accuracy loss

## üìä Memory Usage Breakdown

### Free Tier (512MB RAM):
- **Base System**: ~100MB
- **Python Runtime**: ~50MB
- **Dependencies**: ~100MB
- **Application Code**: ~50MB
- **Available for Model**: ~212MB
- **GoEmotions Model**: ~300-400MB ‚ùå (Too large)
- **DistilRoBERTa Model**: ~200-250MB ‚úÖ (Fits!)

### With Lazy Loading:
- **Startup Memory**: ~300MB ‚úÖ (Fits in 512MB)
- **After First Request**: ~500-600MB ‚ö†Ô∏è (May exceed free tier)
- **Solution**: Use lighter model or upgrade to paid tier

## üîß Configuration Options

### Option 1: Use Lighter Model (Recommended for Free Tier)

Update `emotion_analyzer_v2.py` to use lighter model by default:

```python
def __init__(self):
    # Use lighter model for free tier
    self.model_name = "j-hartmann/emotion-english-distilroberta-base"
    self.classifier = None
    self._model_loaded = False
```

**Pros**:
- ‚úÖ Fits in 512MB free tier
- ‚úÖ Faster startup
- ‚úÖ Lower memory usage

**Cons**:
- ‚ö†Ô∏è Only 7 emotions (vs 27)
- ‚ö†Ô∏è Less nuanced analysis

### Option 2: Keep GoEmotions with Lazy Loading (Current)

**Pros**:
- ‚úÖ 27 emotion labels
- ‚úÖ More nuanced analysis
- ‚úÖ Better accuracy

**Cons**:
- ‚ö†Ô∏è May still exceed 512MB after loading
- ‚ö†Ô∏è First request is slower

### Option 3: Upgrade to Paid Tier

**Pros**:
- ‚úÖ More RAM (1GB+ on starter plan)
- ‚úÖ Can use full GoEmotions model
- ‚úÖ Better performance
- ‚úÖ No memory constraints

**Cons**:
- ‚ö†Ô∏è Costs money ($7/month for starter)

## üöÄ Recommended Setup for Free Tier

### Current Implementation (Lazy Loading):
1. ‚úÖ Model loads on first request
2. ‚úÖ No memory usage during startup
3. ‚úÖ Service starts successfully
4. ‚ö†Ô∏è First request may be slow (model loading)
5. ‚ö†Ô∏è May still exceed memory after loading

### Alternative: Use Lighter Model

If memory issues persist, switch to lighter model:

1. **Update model name** in `emotion_analyzer_v2.py`
2. **Update emotion labels** to match 7 emotions
3. **Test on free tier**
4. **Monitor memory usage**

## üìù Environment Variables

### Memory Optimization Settings:

```env
# Use lighter model for free tier
USE_LIGHT_MODEL=true

# Model loading settings
MODEL_LOAD_TIMEOUT=60
MODEL_MEMORY_LIMIT=400  # MB
```

## üêõ Troubleshooting

### Issue: Still Getting Out of Memory

**Solution 1**: Use lighter model
```python
# In emotion_analyzer_v2.py
self.model_name = "j-hartmann/emotion-english-distilroberta-base"
```

**Solution 2**: Reduce workers
```bash
# In start command
gunicorn app.main:app --workers 1 --threads 1 ...
```

**Solution 3**: Upgrade to paid tier
- Starter plan: $7/month, 1GB RAM
- Professional plan: $25/month, 2GB RAM

### Issue: First Request Times Out

**Solution**: Increase timeout
```bash
# In start command
--timeout 180  # Increase from 120 to 180 seconds
```

### Issue: Model Loading Fails

**Solution**: Check logs and fallback
- Check Render logs for errors
- Model should fallback to lighter model
- Verify model downloads are working

## üìä Memory Monitoring

### Check Memory Usage:

1. **Render Dashboard**: View memory usage in metrics
2. **Logs**: Check for memory warnings
3. **Health Endpoint**: Monitor service health

### Memory Usage Patterns:

- **Startup**: ~300MB (with lazy loading)
- **After First Request**: ~500-600MB (model loaded)
- **Idle**: ~400-500MB (model in memory)
- **Active**: ~500-600MB (processing requests)

## ‚úÖ Success Criteria

### Free Tier Deployment:
- ‚úÖ Service starts without memory errors
- ‚úÖ Health endpoint responds
- ‚úÖ First request loads model successfully
- ‚úÖ Subsequent requests work normally
- ‚ö†Ô∏è May need lighter model if issues persist

### Paid Tier Deployment:
- ‚úÖ Can use full GoEmotions model
- ‚úÖ No memory constraints
- ‚úÖ Better performance
- ‚úÖ Faster response times

## üéØ Recommendations

### For Free Tier:
1. ‚úÖ **Use lazy loading** (already implemented)
2. ‚úÖ **Consider lighter model** if memory issues persist
3. ‚úÖ **Monitor memory usage** in Render Dashboard
4. ‚úÖ **Optimize other services** (reduce workers, etc.)
5. ‚ö†Ô∏è **Consider upgrading** if you need full GoEmotions model

### For Paid Tier:
1. ‚úÖ **Use full GoEmotions model**
2. ‚úÖ **Pre-load model** at startup (faster responses)
3. ‚úÖ **Use multiple workers** for better performance
4. ‚úÖ **Monitor memory usage** and scale as needed

## üîó Related Documentation

- [Render Memory Limits](https://render.com/docs/memory-limits)
- [Render Free Tier](https://render.com/docs/free-tier)
- [Transformers Memory Optimization](https://huggingface.co/docs/transformers/perf_infer_gpu_one)
- [PyTorch Memory Management](https://pytorch.org/docs/stable/notes/cuda.html#memory-management)

---

## üìù Summary

**Current Status**: ‚úÖ Lazy loading implemented
**Memory Usage**: ~300MB at startup, ~500-600MB after model loads
**Free Tier**: May work, but may need lighter model
**Recommendation**: Monitor memory usage and switch to lighter model if needed

**Next Steps**:
1. Deploy with lazy loading
2. Monitor memory usage
3. Switch to lighter model if memory issues persist
4. Consider upgrading to paid tier for full features

---

**Memory optimization implemented! Service should now start successfully on free tier! üöÄ**

